{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/truthisneverlinear/attention-u-net-pytorch/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import random\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH= \"/Users/srikeshnagoji/Documents/PythonWorkSpace/jupyter_lab_workspace/PES/CAPSTONE/kaggle_3m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"/Users/srikeshnagoji/Documents/PythonWorkSpace/jupyter_lab_workspace/PES/CAPSTONE/kaggle_3m/TCGA_CS_4941_19960909/TCGA_CS_4941_19960909_1.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_LEN = len(BASE_PATH) + len(\"/TCGA_CS_4941_19960909/TCGA_CS_4941_19960909_\")\n",
    "END_LEN = len(\".tif\")\n",
    "END_MASK_LEN = len(\"_mask.tif\")\n",
    "\n",
    "IMG_SIZE = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for dir_ in os.listdir(BASE_PATH):\n",
    "    dir_path = os.path.join(BASE_PATH, dir_)\n",
    "    if os.path.isdir(dir_path):\n",
    "        for filename in os.listdir(dir_path):\n",
    "            img_path = os.path.join(dir_path, filename)\n",
    "            data.append([dir_, img_path])\n",
    "    else:\n",
    "        print(f\"[INFO] This is not a dir --> {dir_path}\")\n",
    "        \n",
    "df = pd.DataFrame(data, columns=[\"dir_name\", \"image_path\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs = df[~df[\"image_path\"].str.contains(\"mask\")]\n",
    "df_masks = df[df[\"image_path\"].str.contains(\"mask\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs.iloc[0,1][BASE_LEN: -END_LEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = sorted(df_imgs[\"image_path\"].values, key= lambda x: int((x[BASE_LEN: -END_LEN])))\n",
    "masks = sorted(df_masks[\"image_path\"].values, key=lambda x: int((x[BASE_LEN: -END_MASK_LEN])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "idx = random.randint(0, len(imgs)-1)\n",
    "print(f\"This image *{imgs[idx]}*\\n Belongs to the mask *{masks[idx]}*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final dataframe\n",
    "dff = pd.DataFrame({\"patient\": df_imgs.dir_name.values,\n",
    "                   \"image_path\": imgs,\n",
    "                   \"mask_path\": masks})\n",
    "\n",
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.iloc[0,2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_neg_diagnosis(mask_path):\n",
    "    val = np.max(cv2.imread(mask_path))\n",
    "    if val > 0: return 1\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff[\"diagnosis\"] = dff[\"mask_path\"].apply(lambda x: pos_neg_diagnosis(x))\n",
    "\n",
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Amount of patients: \", len(set(dff.patient)))\n",
    "print(\"Amount of records: \", len(dff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import sklearn as sk\n",
    "import sys\n",
    "has_gpu = torch.cuda.is_available()\n",
    "has_mps = getattr(torch,'has_mps',False)\n",
    "device = \"mps\" if getattr(torch,'has_mps',False) \\\n",
    "    else \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(\"GPU is\", \"available\" if has_gpu else \"NOT AVAILABLE\")\n",
    "print(\"MPS (Apple Metal) is\", \"AVAILABLE\" if has_mps else \"NOT AVAILABLE\")\n",
    "print(f\"Target device is {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainMRIDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.df.iloc[idx, 1])\n",
    "        mask = cv2.imread(self.df.iloc[idx, 2], 0)\n",
    "        \n",
    "        augmented = self.transform(image=image,\n",
    "                                   mask=mask)\n",
    "        \n",
    "        image = augmented[\"image\"]\n",
    "        mask = np.expand_dims(augmented[\"mask\"], axis=0)\n",
    "        \n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 128\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.Resize(width = PATCH_SIZE, height = PATCH_SIZE, p=1.0),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.Transpose(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.01, scale_limit=0.04, rotate_limit=0, p=0.25),\n",
    "\n",
    "    A.Normalize(p=1.0),\n",
    "    ToTensorV2(),\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(dff, stratify=dff.diagnosis, test_size=0.1)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "\n",
    "train_df, test_df = train_test_split(train_df, stratify=train_df.diagnosis, test_size=0.12)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"Train: {train_df.shape} \\nVal: {val_df.shape} \\nTest: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BrainMRIDataset(train_df, transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=26, shuffle=True)\n",
    "\n",
    "val_dataset = BrainMRIDataset(val_df, transform=transform)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=26,  shuffle=True)\n",
    "\n",
    "test_dataset = BrainMRIDataset(test_df, transform=transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=26,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_aug(inputs, nrows=5, ncols=5, norm=False):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplots_adjust(wspace=0., hspace=0.)\n",
    "    i_ = 0\n",
    "    \n",
    "    if len(inputs) > 25:\n",
    "        inputs = inputs[:25]\n",
    "        \n",
    "    for idx in range(len(inputs)):\n",
    "    \n",
    "        # normalization\n",
    "        if norm:           \n",
    "            img = inputs[idx].numpy().transpose(1,2,0)\n",
    "            mean = [0.485, 0.456, 0.406]\n",
    "            std = [0.229, 0.224, 0.225] \n",
    "            img = (img*std+mean).astype(np.float32)\n",
    "            \n",
    "        else:\n",
    "            img = inputs[idx].numpy().astype(np.float32)\n",
    "            img = img[0,:,:]\n",
    "        \n",
    "        plt.subplot(nrows, ncols, i_+1)\n",
    "        plt.imshow(img); \n",
    "        plt.axis('off')\n",
    " \n",
    "        i_ += 1\n",
    "        \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, masks = next(iter(train_dataloader))\n",
    "print(images.shape, masks.shape)\n",
    "\n",
    "show_aug(images)\n",
    "show_aug(masks, norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTENTION UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "                                  nn.Conv2d(ch_in, ch_out,\n",
    "                                            kernel_size=3, stride=1,\n",
    "                                            padding=1, bias=True),\n",
    "                                  nn.BatchNorm2d(ch_out),\n",
    "                                  nn.ReLU(inplace=True),\n",
    "                                  nn.Conv2d(ch_out, ch_out,\n",
    "                                            kernel_size=3, stride=1,\n",
    "                                            padding=1, bias=True),\n",
    "                                  nn.BatchNorm2d(ch_out),\n",
    "                                  nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpConvBlock(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super().__init__()\n",
    "        self.up = nn.Sequential(\n",
    "                                nn.Upsample(scale_factor=2),\n",
    "                                nn.Conv2d(ch_in, ch_out,\n",
    "                                         kernel_size=3,stride=1,\n",
    "                                         padding=1, bias=True),\n",
    "                                nn.BatchNorm2d(ch_out),\n",
    "                                nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x = self.up(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, f_g, f_l, f_int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.w_g = nn.Sequential(\n",
    "                                nn.Conv2d(f_g, f_int,\n",
    "                                         kernel_size=1, stride=1,\n",
    "                                         padding=0, bias=True),\n",
    "                                nn.BatchNorm2d(f_int)\n",
    "        )\n",
    "        \n",
    "        self.w_x = nn.Sequential(\n",
    "                                nn.Conv2d(f_l, f_int,\n",
    "                                         kernel_size=1, stride=1,\n",
    "                                         padding=0, bias=True),\n",
    "                                nn.BatchNorm2d(f_int)\n",
    "        )\n",
    "        \n",
    "        self.psi = nn.Sequential(\n",
    "                                nn.Conv2d(f_int, 1,\n",
    "                                         kernel_size=1, stride=1,\n",
    "                                         padding=0,  bias=True),\n",
    "                                nn.BatchNorm2d(1),\n",
    "                                nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, g, x):\n",
    "        g1 = self.w_g(g)\n",
    "        x1 = self.w_x(x)\n",
    "        psi = self.relu(g1+x1)\n",
    "        psi = self.psi(psi)\n",
    "        \n",
    "        return psi*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionUNet(nn.Module):\n",
    "    def __init__(self, n_classes=1, in_channel=3, out_channel=1):\n",
    "        super().__init__() \n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv1 = ConvBlock(ch_in=in_channel, ch_out=64)\n",
    "        self.conv2 = ConvBlock(ch_in=64, ch_out=128)\n",
    "        self.conv3 = ConvBlock(ch_in=128, ch_out=256)\n",
    "        self.conv4 = ConvBlock(ch_in=256, ch_out=512)\n",
    "        self.conv5 = ConvBlock(ch_in=512, ch_out=1024)\n",
    "        \n",
    "        self.up5 = UpConvBlock(ch_in=1024, ch_out=512)\n",
    "        self.att5 = AttentionBlock(f_g=512, f_l=512, f_int=256)\n",
    "        self.upconv5 = ConvBlock(ch_in=1024, ch_out=512)\n",
    "        \n",
    "        self.up4 = UpConvBlock(ch_in=512, ch_out=256)\n",
    "        self.att4 = AttentionBlock(f_g=256, f_l=256, f_int=128)\n",
    "        self.upconv4 = ConvBlock(ch_in=512, ch_out=256)\n",
    "        \n",
    "        self.up3 = UpConvBlock(ch_in=256, ch_out=128)\n",
    "        self.att3 = AttentionBlock(f_g=128, f_l=128, f_int=64)\n",
    "        self.upconv3 = ConvBlock(ch_in=256, ch_out=128)\n",
    "        \n",
    "        self.up2 = UpConvBlock(ch_in=128, ch_out=64)\n",
    "        self.att2 = AttentionBlock(f_g=64, f_l=64, f_int=32)\n",
    "        self.upconv2 = ConvBlock(ch_in=128, ch_out=64)\n",
    "        \n",
    "        self.conv_1x1 = nn.Conv2d(64, out_channel,\n",
    "                                  kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # encoder\n",
    "        x1 = self.conv1(x)\n",
    "        \n",
    "        x2 = self.maxpool(x1)\n",
    "        x2 = self.conv2(x2)\n",
    "        \n",
    "        x3 = self.maxpool(x2)\n",
    "        x3 = self.conv3(x3)\n",
    "        \n",
    "        x4 = self.maxpool(x3)\n",
    "        x4 = self.conv4(x4)\n",
    "        \n",
    "        x5 = self.maxpool(x4)\n",
    "        x5 = self.conv5(x5)\n",
    "        \n",
    "        # decoder + concat\n",
    "        d5 = self.up5(x5)\n",
    "        x4 = self.att5(g=d5, x=x4)\n",
    "        d5 = torch.concat((x4, d5), dim=1)\n",
    "        d5 = self.upconv5(d5)\n",
    "        \n",
    "        d4 = self.up4(d5)\n",
    "        x3 = self.att4(g=d4, x=x3)\n",
    "        d4 = torch.concat((x3, d4), dim=1)\n",
    "        d4 = self.upconv4(d4)\n",
    "        \n",
    "        d3 = self.up3(d4)\n",
    "        x2 = self.att3(g=d3, x=x2)\n",
    "        d3 = torch.concat((x2, d3), dim=1)\n",
    "        d3 = self.upconv3(d3)\n",
    "        \n",
    "        d2 = self.up2(d3)\n",
    "        x1 = self.att2(g=d2, x=x1)\n",
    "        d2 = torch.concat((x1, d2), dim=1)\n",
    "        d2 = self.upconv2(d2)\n",
    "        \n",
    "        d1 = self.conv_1x1(d2)\n",
    "        \n",
    "        return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_unet = AttentionUNet(n_classes=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check sanity\n",
    "output = torch.randn(1,3,256,256).to(device)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEGMENTATION METRIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef_metric(inputs, target):\n",
    "    intersection = 2.0 * (target*inputs).sum()\n",
    "    union = target.sum() + inputs.sum()\n",
    "    if target.sum() == 0 and inputs.sum() == 0:\n",
    "        return 1.0 \n",
    "    return intersection/union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segmentation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "DiceLoss()(torch.tensor([0.7, 1., 1.]), \n",
    "              torch.tensor([1.,1.,1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"model_unet_3p.pt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, model, train_loader, val_loader, train_loss, optimizer, lr_scheduler, num_epochs):\n",
    "    print(f\"[INFO] Model is initializing... {model_name}\")\n",
    "    \n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        losses = []\n",
    "        train_iou = []\n",
    "        \n",
    "        for i_step, (data, target) in enumerate(tqdm(train_loader)):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            outputs = model(data)\n",
    "            \n",
    "            out_cut = np.copy(outputs.data.cpu().numpy())\n",
    "            out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
    "            out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n",
    "            \n",
    "            train_dice = dice_coef_metric(out_cut, target.data.cpu().numpy())\n",
    "            \n",
    "            loss = train_loss(outputs, target)\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            train_iou.append(train_dice)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        val_mean_iou = compute_iou(model, val_loader)\n",
    "        \n",
    "        loss_history.append(np.array(losses).mean())\n",
    "        train_history.append(np.array(train_iou).mean())\n",
    "        val_history.append(val_mean_iou)\n",
    "        \n",
    "        \n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': np.array(losses).mean(),\n",
    "                    }, PATH)\n",
    "        \n",
    "        print(\"Epoch [%d]\" % (epoch))\n",
    "        print(\"Mean loss on train:\", np.array(losses).mean(), \n",
    "              \"\\nMean DICE on train:\", np.array(train_iou).mean(), \n",
    "              \"\\nMean DICE on validation:\", val_mean_iou)\n",
    "        \n",
    "    return loss_history, train_history, val_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(model, loader, threshold=0.3):\n",
    "    valloss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i_step, (data, target) in enumerate(loader):\n",
    "            \n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            outputs = model(data)\n",
    "\n",
    "            out_cut = np.copy(outputs.data.cpu().numpy())\n",
    "            out_cut[np.nonzero(out_cut < threshold)] = 0.0\n",
    "            out_cut[np.nonzero(out_cut >= threshold)] = 1.0\n",
    "            picloss = dice_coef_metric(out_cut, target.data.cpu().numpy())\n",
    "            valloss += picloss\n",
    "\n",
    "    return valloss / i_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adamax(attention_unet.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "num_ep = 50\n",
    "# after 30 does not improve much\n",
    "\n",
    "aun_lh, aun_th, aun_vh = train_model(\"Attention UNet\", attention_unet, train_dataloader, val_dataloader, DiceLoss(), opt, False, num_ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_name,\n",
    "                        train_history, val_history, \n",
    "                        num_epochs):\n",
    "    \n",
    "    x = np.arange(num_epochs)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x, train_history, label='train dice', lw=3, c=\"springgreen\")\n",
    "    plt.plot(x, val_history, label='validation dice', lw=3, c=\"deeppink\")\n",
    "\n",
    "    plt.title(f\"{model_name}\", fontsize=15)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.xlabel(\"Epoch\", fontsize=15)\n",
    "    plt.ylabel(\"DICE\", fontsize=15)\n",
    "\n",
    "    fn = str(int(time.time())) + \".png\"\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_history(\"Attention U-Net\", aun_th, aun_vh, num_ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(num_ep), aun_lh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iou = compute_iou(attention_unet, test_dataloader)\n",
    "print(f\"\"\"Attention U-Net\\nMean IoU of the test images - {np.around(test_iou, 2)*100}%\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different Loss Functions and Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: copy paste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d9fe2f040c093e6866475fa96b829ef49234fde465e00105dee1d04d2ea6c922"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
